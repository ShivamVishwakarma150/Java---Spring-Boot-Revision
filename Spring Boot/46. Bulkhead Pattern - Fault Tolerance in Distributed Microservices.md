# **Fault Tolerant Microservices: Part 2 - Bulkhead Pattern**
![alt text](/images/image-1.png)
### **1. Core Concept: Protecting Your Services**
![alt text](/images/image.png)
The goal of fault tolerance is to build resilient systems that can handle failures and traffic spikes gracefully. This lecture focuses on the **Bulkhead Pattern** and how it differs from the Rate Limiter.

| Feature | Rate Limiter | Bulkhead Pattern |
| :--- | :--- | :--- |
| **Protects Against** | Excessive requests from **clients** | Resource exhaustion from **downstream services** or noisy neighbors |
| **Focus** | **Request Rate** (e.g., 10 requests/minute) | **Concurrent Requests** (e.g., 3 concurrent calls) |
| **Primary Concern** | How many requests in a time window? | How many threads are busy at the same time? |

---

### **2. The Bulkhead Pattern: Two Key Use Cases**

Inspired by ship compartments that prevent a leak from sinking the entire vessel, the bulkhead pattern isolates failures in one part of a system.

#### **Use Case 1: Protecting a Downstream Service (Semaphore Bulkhead)**

*   **Scenario:** Your `order-service` calls a lightweight `product-service` that can only handle **3 concurrent requests**.
*   **Problem:** A 4th concurrent request would overload the downstream service.
*   **Solution:** Use a **Semaphore Bulkhead**.
    *   It acts as a gatekeeper with a counter (a semaphore lock).
    *   Only `N` threads (e.g., 3) are allowed into the "critical section" (the code that calls the downstream API) at once.
    *   Additional requests are either **rejected immediately** or asked to **wait briefly** for a slot to free up.

#### **Use Case 2: Preventing Noisy Neighbors (Thread Pool Bulkhead)**

*   **Scenario:** Your `order-service` has two endpoints:
    *   **API 1:** Calls a fast `product-service` (100ms response).
    *   **API 2:** Calls a slow `payment-service` (5s response).
*   **The "Noisy Neighbor" Problem:** A traffic spike to **API 2** causes many requests. Each request blocks a thread for 5 seconds. Eventually, **all threads** in the service's common pool are blocked by slow `payment-service` calls.
*   **Result:** Even requests to the fast **API 1** start failing or timing out because there are no free threads left to process them. One "noisy" API cripples the entire service.
*   **Solution:** Use a **Thread Pool Bulkhead**.
    *   Assign a **dedicated, limited thread pool** to the call for the slow service (`payment-service`).
    *   For example, only 5 threads max can be used for payment calls.
    *   **Benefit:** Even if the payment service is flooded and slow, it can only consume its allocated 5 threads. The remaining threads in the main pool are free to handle requests for the fast `product-service`, isolating the failure.

---

### **3. Implementation with Resilience4J**

#### **A. Semaphore Bulkhead**

**How it Works:** Internally uses a **semaphore lock** to manage a counter of permitted concurrent executions.

**1. Code Implementation (`OrderService.java`)**
```java
@Service
public class OrderService {

    @Bulkhead(name = "productService", type = Bulkhead.Type.SEMAPHORE, fallbackMethod = "productFallback")
    public String getProduct(String productId) {
        // This is the "critical section"
        // Code to call downstream product-service API
        return productClient.getProductById(productId);
    }

    // Fallback method signature must match original method
    private String productFallback(String productId, Throwable t) {
        return "Product service is busy. Please try again later. Fallback product info for: " + productId;
    }
}
```

**2. Configuration (`application.properties`)**
```properties
# Configure the Semaphore Bulkhead instance named 'productService'
resilience4j.bulkhead.instances.productService.max-concurrent-calls=2
resilience4j.bulkhead.instances.productService.max-wait-duration=0
```
*   `max-concurrent-calls`: The maximum number of parallel calls allowed (the semaphore count).
*   `max-wait-duration`: How long a thread should wait for a permit before being rejected. `0` means fail immediately. Can be set to, e.g., `500ms`, `2s`.

#### **B. Thread Pool Bulkhead**

**How it Works:** Internally creates a dedicated `ThreadPoolExecutor` for the annotated method. The AOP proxy submits the method's execution to this pool instead of the common application pool.

**1. Code Implementation (`OrderService.java`)**
```java
@Service
public class OrderService {

    @Bulkhead(name = "productService", type = Bulkhead.Type.THREAD_POOL, fallbackMethod = "productFallback")
    public CompletableFuture<String> getProduct(String productId) {
        // The entire method body is submitted to the bulkhead's thread pool
        System.out.println("Thread: " + Thread.currentThread().getName());
        String productInfo = productClient.getProductById(productId);
        return CompletableFuture.completedFuture(productInfo);
    }

    // Fallback method returns the same type (CompletableFuture<String>)
    private CompletableFuture<String> productFallback(String productId, Throwable t) {
        return CompletableFuture.completedFuture("Product service is busy. Fallback for: " + productId);
    }
}
```
**⚠️ Important Notes:**
*   **Return Type must be `CompletableFuture<T>`.** This is because the AOP proxy submits the task asynchronously to the thread pool and returns a Future handle immediately.
*   **Use `CompletableFuture.completedFuture()`** to wrap your result. **Do NOT use `supplyAsync`** inside the method, as that would manually submit to a different pool, breaking the bulkhead logic. Let the AOP handle the async execution.

**2. Configuration (`application.properties`)**
```properties
# Configure the Thread Pool Bulkhead instance named 'productService'
resilience4j.thread-pool-bulkhead.instances.productService.max-thread-pool-size=3
resilience4j.thread-pool-bulkhead.instances.productService.core-thread-pool-size=3
resilience4j.thread-pool-bulkhead.instances.productService.queue-capacity=2
```
*   `core-thread-pool-size`: Number of threads that are always kept alive in the pool.
*   `max-thread-pool-size`: Maximum number of threads the pool can create.
*   `queue-capacity`: The size of the queue for holding tasks when all threads are busy.

**Example Workflow (with above config):**
*   **Thread Pool:** 3 threads max. **Queue:** Holds 2 tasks.
*   You make **6 concurrent calls** to the endpoint.
    *   **3 calls** are immediately picked up by the 3 threads.
    *   **2 calls** are placed in the queue to wait.
    *   **The 6th call** is **rejected immediately** (because the pool is full *and* the queue is full) and triggers the `fallbackMethod`.

---

### **4. Bonus: Time Limiter (Brief Overview)**

*   **Purpose:** To prevent **asynchronous** or **reactive** (WebFlux) calls from hanging indefinitely.
*   **For Blocking Calls (RestTemplate):** Timeouts are handled by the HTTP client itself (e.g., `connect-timeout`, `read-timeout` properties).
*   **For Non-Blocking/Async Calls:** A "fire-and-forget" task submitted to a thread pool could run forever. The Time Limiter ensures such tasks are interrupted or timed out after a specified duration, freeing up resources.
*   **This is most relevant in reactive programming (Project Reactor - Mono/Flux)** and will be covered in detail with WebFlux.

---

### **5. Key Takeaways & Best Practices**

1.  **Choose the Right Pattern:**
    *   Use **Rate Limiter** to protect your API from being overwhelmed by too many client requests.
    *   Use **Semaphore Bulkhead** to protect a fragile downstream service from too many concurrent calls from you.
    *   Use **Thread Pool Bulkhead** to isolate a slow or faulty downstream service, preventing it from consuming all your application's threads (Noisy Neighbor).

2.  **Understand Thread Pools:** A solid understanding of `ThreadPoolExecutor`, its core/max sizes, and queueing behavior is **essential** to correctly configure and debug the Thread Pool Bulkhead.

3.  **Let AOP Handle It:** The `@Bulkhead` annotation and Resilience4J AOP handle the complex threading logic. Don't try to manually create `CompletableFuture.supplyAsync()` inside your bulkhead method.

4.  **Practice:** The best way to understand is to run the code yourself! Change the configuration values (like `queue-capacity` and `max-wait-duration`) and observe how the system behavior changes under load.